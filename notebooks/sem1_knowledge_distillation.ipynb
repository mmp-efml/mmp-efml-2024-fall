{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "id": "TkI5z7m1yy05"
   },
   "outputs": [],
   "source": [
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "oVSdThqRyy08"
   },
   "source": [
    "Семинар 1: Knowledge Distillation\n",
    "===============================\n",
    "\n",
    "**Материал взят из [Источника](https://github.com/AlexandrosChrtn)**\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowledge distillation - это метод, который позволяет передавать знания от больших, требующих больших вычислительных затрат моделей к более мелким без существенной потери точности. Это позволяет использовать менее мощное аппаратное обеспечение, что ускоряет и повышает эффективность инференса.\n",
    "\n",
    "В этом руководстве мы проведем ряд экспериментов, направленных на повышение точности работы маленькой нейронной сети **(студента)**, дистиллируя знания из большой сети **(учителя)**. Вычислительные затраты и скорость маленькой сети останутся неизменными, наше вмешательство фокусируется только на весах модели, а не на forward pass (прямом проходе). Knowledge distillation находит применение в таких устройствах, как дроны и мобильные телефоны.\n",
    " \n",
    " \n",
    "В этом ноутбуке мы узнаем:\n",
    "\n",
    "- Как модифицировать классы моделей для извлечения скрытых представлений и использования их для дальнейших вычислений\n",
    "\n",
    "- Как повысить качество маленькой модели за счет использования более сложной модели в качестве учителей"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "id": "BDQvCVMyyy0-"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision.datasets as datasets\n",
    "\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import random\n",
    "\n",
    "def set_global_seed(seed: int) -> None:\n",
    "    \"\"\"\n",
    "    Set global seed for reproducibility.\n",
    "    \"\"\"\n",
    "\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False\n",
    "\n",
    "# Check if GPU is available, and if not, use the CPU\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RKxfK1Z0yy0-"
   },
   "source": [
    "CIFAR-10\n",
    "================\n",
    "\n",
    "В качестве данных мы будем использовать **CIFAR-10**, один из самых известных датасетов для классификации изображенией\n",
    "\n",
    "![Example of CIFAR-10\n",
    "images](https://pytorch.org/tutorials//../_static/img/cifar10.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "id": "s6cZbR-Hyy0_"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Below we are preprocessing data for CIFAR-10. We use an arbitrary batch size of 128.\n",
    "transforms_cifar = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]), # ImageNet normalize\n",
    "])\n",
    "\n",
    "# Loading the CIFAR-10 dataset:\n",
    "train_dataset = datasets.CIFAR10(root='./data', train=True, download=True, transform=transforms_cifar)\n",
    "test_dataset = datasets.CIFAR10(root='./data', train=False, download=True, transform=transforms_cifar)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "46VJoKNqyy1A"
   },
   "outputs": [],
   "source": [
    "#Dataloaders\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=128, shuffle=True, num_workers=2)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=128, shuffle=False, num_workers=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Определение классов моделей и полезные функции\n",
    "============================================\n",
    "\n",
    "Далее нам нужно закодить классы реализующие модели классификации. Мы зададим две сверточные архитектуры (CNNs) с различным количеством сверточных слоев, они служат для извлечения признаков, и с полносвязными классификаторами с 10 классами. Для модели студента количество фильтров и нейронов меньше, чем для модели учителя."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Deeper neural network class to be used as teacher:\n",
    "class DeepNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(DeepNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(2048, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "zGIpts3Wyy1A"
   },
   "outputs": [],
   "source": [
    "# Lightweight neural network class to be used as student:\n",
    "class LightNN(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(LightNN, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(16, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        x = torch.flatten(x, 1)\n",
    "        x = self.classifier(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![Train both networks with Cross-Entropy. The student will be used as a\n",
    "baseline:](https://pytorch.org/tutorials//../_static/img/knowledge_distillation/ce_only.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Обучение и тест\n",
    "==============="
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uNb0gB4syy1B"
   },
   "source": [
    "Мы используем 2 функции, которые помогают нам получать и оценивать результаты в нашей\n",
    "первоначальной задаче классификации.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "AjDZcE4Nyy1B"
   },
   "outputs": [],
   "source": [
    "def train(model, train_loader, epochs, learning_rate, device):\n",
    "    \"\"\"\n",
    "    `model`: A model instance to train (update its weights) via this\n",
    "    function.\n",
    "    `train_loader`: We defined our `train_loader` above, and its job is\n",
    "    to feed the data into the model.\n",
    "    `epochs`: How many times we loop over the dataset.\n",
    "    `learning_rate`: The learning rate determines how large our steps\n",
    "    towards convergence should be. Too large or too small steps can be\n",
    "    detrimental.\n",
    "    `device`: Determines the device to run the workload on. Can be\n",
    "    either CPU or GPU depending on availability.\n",
    "    \"\"\"\n",
    "    \n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            # inputs: A collection of batch_size images\n",
    "            # labels: A vector of dimensionality batch_size with integers denoting class of each image\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # outputs: Output of the network for the collection of images. A tensor of dimensionality batch_size x num_classes\n",
    "            # labels: The actual labels of the images. Vector of dimensionality batch_size\n",
    "            loss = criterion(outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss / len(train_loader)}\")\n",
    "\n",
    "def test(model, test_loader, device):\n",
    "    \"\"\"\n",
    "    `model`: A model instance to train (update its weights) via this\n",
    "    function.\n",
    "    `test_loader`: We defined our `test_loader` above, and its job is\n",
    "    to feed the data into the model.\n",
    "    `device`: Determines the device to run the workload on. Can be\n",
    "    either CPU or GPU depending on availability.\n",
    "    \"\"\"\n",
    "    \n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jNlK1nEoyy1B"
   },
   "source": [
    "Cross-entropy (baseline)\n",
    "==================\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "tkspPpcDyy1B"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.3256008115875753\n",
      "Epoch 2/10, Loss: 0.8632667924437072\n",
      "Epoch 3/10, Loss: 0.6770264405728607\n",
      "Epoch 4/10, Loss: 0.5343857654525191\n",
      "Epoch 5/10, Loss: 0.41441617887038407\n",
      "Epoch 6/10, Loss: 0.3134289937822715\n",
      "Epoch 7/10, Loss: 0.22761023200838768\n",
      "Epoch 8/10, Loss: 0.17139672357446092\n",
      "Epoch 9/10, Loss: 0.14778140834187303\n",
      "Epoch 10/10, Loss: 0.1222293549896125\n",
      "Test Accuracy: 74.23%\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the teacher network:\n",
    "\n",
    "set_global_seed(42)\n",
    "nn_deep = DeepNN(num_classes=10).to(device)\n",
    "train(nn_deep, train_loader, epochs=10, learning_rate=0.001, device=device)\n",
    "test_accuracy_deep = test(nn_deep, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "kVBxkFSgyy1D"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.4668227635381166\n",
      "Epoch 2/10, Loss: 1.1526997007067552\n",
      "Epoch 3/10, Loss: 1.0217017305781468\n",
      "Epoch 4/10, Loss: 0.9182852922802995\n",
      "Epoch 5/10, Loss: 0.844304761465858\n",
      "Epoch 6/10, Loss: 0.7765299892791396\n",
      "Epoch 7/10, Loss: 0.7096788134721234\n",
      "Epoch 8/10, Loss: 0.649937776348475\n",
      "Epoch 9/10, Loss: 0.5978364141853264\n",
      "Epoch 10/10, Loss: 0.5463351162955584\n",
      "Test Accuracy: 70.23%\n"
     ]
    }
   ],
   "source": [
    "# Instantiate the student network:\n",
    "\n",
    "set_global_seed(42)\n",
    "nn_light = LightNN(num_classes=10).to(device)\n",
    "\n",
    "train(nn_light, train_loader, epochs=10, learning_rate=0.001, device=device)\n",
    "test_accuracy_light_ce = test(nn_light, test_loader, device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AG44rS1eyy1C"
   },
   "source": [
    "При сравнении результатов нам важно знать число параметров модели\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "id": "cyTTESARyy1C"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DeepNN parameters: 1,186,986\n",
      "LightNN parameters: 267,738\n"
     ]
    }
   ],
   "source": [
    "total_params_deep = \"{:,}\".format(sum(p.numel() for p in nn_deep.parameters()))\n",
    "print(f\"DeepNN parameters: {total_params_deep}\")\n",
    "total_params_light = \"{:,}\".format(sum(p.numel() for p in nn_light.parameters()))\n",
    "print(f\"LightNN parameters: {total_params_light}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "EPzrUcfqyy1D"
   },
   "source": [
    "Без использования Knowledge distillation мы получим следующую точность на тесте, то есть наш baseline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "CmLokkoxyy1D"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher accuracy: 74.23%\n",
      "Student accuracy: 70.23%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Teacher accuracy: {test_accuracy_deep:.2f}%\")\n",
    "print(f\"Student accuracy: {test_accuracy_light_ce:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Knowledge distillation run\n",
    "==========================\n",
    "\n",
    "\n",
    "Теперь давайте попробуем повысить точность на тесте для сети студента, дистиллировав в нее учителя. Knowledge distillation - простой метод для достижения этой цели, основанный на том факте, что обе сети выводят распределение вероятностей по нашим классам. Следовательно, обе сети используют одинаковое количество выходных нейронов. Этот метод работает за счет добавления дополнительного лосса к традиционому Cross-Entropy loss. Предполагается, что выход сети учителя содержит дополнительную информацию, которая может быть использована сетью студента во время обучения.\n",
    "\n",
    "Например, в CIFAR-10 грузовик можно принять за автомобиль или самолет, если у него есть колеса, но маловероятно, что его примут за собаку. Следовательно, имеет смысл предположить, что полезная информация содержится не только в вероятном прогнозе\n",
    "правильно обученного учителя, но и во всем распределении выходных данных. Однако сам по себе Cross-Entropy loss недостаточно использует эту информацию, поскольку активации для маловероятных классов, как правило, настолько малы, что градиенты не приводят к значительному изменению весов."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Dq7feNtgyy1D"
   },
   "source": [
    "![Distillation loss is calculated from the logits of the networks. It\n",
    "only returns gradients to the\n",
    "student:](https://pytorch.org/tutorials//../_static/img/knowledge_distillation/distillation_output_loss.png)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "id": "XtLD63R-yy1D"
   },
   "outputs": [],
   "source": [
    "def train_knowledge_distillation(teacher, student, train_loader, epochs, learning_rate, T, soft_target_loss_weight, ce_loss_weight, device):\n",
    "    \n",
    "    \"\"\"\n",
    "    `T`: Temperature controls the smoothness of the output\n",
    "    distributions. Larger `T` leads to smoother distributions, thus\n",
    "    smaller probabilities get a larger boost.\n",
    "    `soft_target_loss_weight`: A weight assigned to the extra objective\n",
    "    we\\'re about to include.\n",
    "    `ce_loss_weight`: A weight assigned to cross-entropy. Tuning these\n",
    "    weights pushes the network towards optimizing for either objective.\n",
    "    \"\"\"\n",
    "    \n",
    "    ce_loss = nn.CrossEntropyLoss()\n",
    "    optimizer = optim.Adam(student.parameters(), lr=learning_rate)\n",
    "\n",
    "    teacher.eval()  # Teacher set to evaluation mode\n",
    "    student.train() # Student to train mode\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass with the teacher model - do not save gradients here as we do not change the teacher's weights\n",
    "            with torch.no_grad():\n",
    "                teacher_logits = teacher(inputs)\n",
    "\n",
    "            # Forward pass with the student model\n",
    "            student_logits = student(inputs)\n",
    "\n",
    "            #Soften the student logits by applying softmax first and log() second\n",
    "            soft_targets = nn.functional.softmax(teacher_logits / T, dim=-1)\n",
    "            soft_prob = nn.functional.log_softmax(student_logits / T, dim=-1)\n",
    "\n",
    "            # Calculate the soft targets loss. Scaled by T**2 as suggested by the authors of the paper \"Distilling the knowledge in a neural network\"\n",
    "            soft_targets_loss = torch.sum(soft_targets * (soft_targets.log() - soft_prob)) / soft_prob.size()[0] * (T**2)\n",
    "\n",
    "            # Calculate the true label loss\n",
    "            label_loss = ce_loss(student_logits, labels)\n",
    "\n",
    "            # Weighted sum of the two losses\n",
    "            loss = soft_target_loss_weight * soft_targets_loss + ce_loss_weight * label_loss\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss / len(train_loader)}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 2.403964203946731\n",
      "Epoch 2/10, Loss: 1.8924736418687473\n",
      "Epoch 3/10, Loss: 1.6759761016996926\n",
      "Epoch 4/10, Loss: 1.5063083873075598\n",
      "Epoch 5/10, Loss: 1.3776447824809863\n",
      "Epoch 6/10, Loss: 1.2682764351825275\n",
      "Epoch 7/10, Loss: 1.1630251947266366\n",
      "Epoch 8/10, Loss: 1.0745595810968247\n",
      "Epoch 9/10, Loss: 0.9920528576806988\n",
      "Epoch 10/10, Loss: 0.9227680528865141\n",
      "Test Accuracy: 70.34%\n",
      "Teacher accuracy: 74.23%\n",
      "Student accuracy without teacher: 70.23%\n",
      "Student accuracy with CE + KD: 70.34%\n"
     ]
    }
   ],
   "source": [
    "set_global_seed(42)\n",
    "new_nn_light = LightNN(num_classes=10).to(device)\n",
    "\n",
    "# Apply ``train_knowledge_distillation`` with a temperature of 2. Arbitrarily set the weights to 0.75 for CE and 0.25 for distillation loss.\n",
    "train_knowledge_distillation(teacher=nn_deep, student=new_nn_light, train_loader=train_loader, epochs=10, learning_rate=0.001, T=2, soft_target_loss_weight=0.25, ce_loss_weight=0.75, device=device)\n",
    "test_accuracy_light_ce_and_kd = test(new_nn_light, test_loader, device)\n",
    "\n",
    "# Compare the student test accuracy with and without the teacher, after distillation\n",
    "print(f\"Teacher accuracy: {test_accuracy_deep:.2f}%\")\n",
    "print(f\"Student accuracy without teacher: {test_accuracy_light_ce:.2f}%\")\n",
    "print(f\"Student accuracy with CE + KD: {test_accuracy_light_ce_and_kd:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не стесняйтесь экспериментировать с параметром температуры, который управляет гладкостью функции softmax и коэффициентами в функции потерь. В нейронных сетях легко включить дополнительные функции потерь в основные задачи для улучшения обобщающей способности. Давайте попробуем включить оптимизируемый функционал для студента, но теперь давайте сосредоточимся на его скрытых состояниях, а не на выходных слоях. Наша цель - донести информацию из представления учителя до студента, включив наивную функцию потерь, минимизация которой подразумевает, что сглаженные векторы, которые впоследствии передаются в классификаторы, становятся более похожими по мере уменьшения потерь.\n",
    "\n",
    "Конечно, учитель не обновляет свои веса, поэтому минимизация зависит только от веса ученика. Логическим обоснованием этого метода является то, что мы исходим из предположения, что модель учителя имеет лучшее внутреннее представление, которое вряд ли может быть достигнуто студентом без внешнего вмешательства, поэтому мы искусственно подталкиваем студента к имитации внутреннего представления учителя. Однако не ясно, поможет ли это в конечном итоге студенту, потому что использование облегченной сети для достижения этой цели может быть полезным, если предположить, что мы нашли внутреннее представление, которое повышает точность на тесте, но это также может быть вредным, поскольку сети имеют разную архитектуру и сложность. Студент не обладает такой же способностью к обучению, как учитель. Другими словами, нет никаких причин для того, чтобы эти два вектора (вектор студента и вектор учителя) совпадали по каждому компоненту. Ученик мог бы создать внутреннее представление, которое является заменой представления учителя, и это было бы столь же эффективно. Тем не менее, мы все еще можем провести небольшой эксперимент, чтобы выяснить эффективность этого метода. Мы будем использовать значение `CosineEmbeddingLoss`, которое задается следующей формулой:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "![Formula for\n",
    "CosineEmbeddingLoss](https://pytorch.org/tutorials//../_static/img/knowledge_distillation/cosine_embedding_loss.png)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Очевидно, что сначала нам нужно решить одну проблему. Когда мы\n",
    "применяли дистилляцию к выходному слою, мы упомянули, что обе сети\n",
    "имеют одинаковое количество нейронов, равное количеству классов.\n",
    "Однако это не относится к слою, следующему за нашими сверточными\n",
    "слоями. Здесь у учителя больше нейронов, чем у ученика, после\n",
    "выравнивания последнего сверточного слоя. Наша функция потерь принимает\n",
    "в качестве входных данных два вектора одинаковой размерности, поэтому нам нужно\n",
    "каким-то образом сопоставить их. Мы решим эту проблему, включив avgPoll, следующий за сверточным слоем учителя, чтобы уменьшить его\n",
    "размерность в соответствии с размером студента.\n",
    "\n",
    "Чтобы продолжить, мы немного изменим классы моделей. Теперь\n",
    "функция forward возвращает не только логиты сети, но и\n",
    "сглаженное скрытое представление после сверточного слоя. Мы\n",
    "добавили вышеупомянутое изменение:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "jgsRAKQ0yy1D"
   },
   "outputs": [],
   "source": [
    "class ModifiedDeepNNCosine(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ModifiedDeepNNCosine, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 128, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(128, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(64, 64, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.Conv2d(64, 32, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(2048, 512),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(512, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        flattened_conv_output = torch.flatten(x, 1)\n",
    "        x = self.classifier(flattened_conv_output)\n",
    "        flattened_conv_output_after_pooling = torch.nn.functional.avg_pool1d(flattened_conv_output, 2)\n",
    "        return x, flattened_conv_output_after_pooling\n",
    "\n",
    "# Create a similar student class where we return a tuple. We do not apply pooling after flattening.\n",
    "class ModifiedLightNNCosine(nn.Module):\n",
    "    def __init__(self, num_classes=10):\n",
    "        super(ModifiedLightNNCosine, self).__init__()\n",
    "        self.features = nn.Sequential(\n",
    "            nn.Conv2d(3, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "            nn.Conv2d(16, 16, kernel_size=3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(kernel_size=2, stride=2),\n",
    "        )\n",
    "        self.classifier = nn.Sequential(\n",
    "            nn.Linear(1024, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(0.1),\n",
    "            nn.Linear(256, num_classes)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.features(x)\n",
    "        flattened_conv_output = torch.flatten(x, 1)\n",
    "        x = self.classifier(flattened_conv_output)\n",
    "        return x, flattened_conv_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Norm of 1st layer for deep_nn: 7.4885735511779785\n",
      "Norm of 1st layer for modified_deep_nn: 7.4885735511779785\n",
      "Norm of 1st layer: 2.327361822128296\n"
     ]
    }
   ],
   "source": [
    "# We do not have to train the modified deep network from scratch of course, we just load its weights from the trained instance\n",
    "modified_nn_deep = ModifiedDeepNNCosine(num_classes=10).to(device)\n",
    "modified_nn_deep.load_state_dict(nn_deep.state_dict())\n",
    "\n",
    "# Once again ensure the norm of the first layer is the same for both networks\n",
    "print(\"Norm of 1st layer for deep_nn:\", torch.norm(nn_deep.features[0].weight).item())\n",
    "print(\"Norm of 1st layer for modified_deep_nn:\", torch.norm(modified_nn_deep.features[0].weight).item())\n",
    "\n",
    "# Initialize a modified lightweight network with the same seed as our other lightweight instances. This will be trained from scratch to examine the effectiveness of cosine loss minimization.\n",
    "set_global_seed(42)\n",
    "modified_nn_light = ModifiedLightNNCosine(num_classes=10).to(device)\n",
    "print(\"Norm of 1st layer:\", torch.norm(modified_nn_light.features[0].weight).item())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "gJEa58hQyy1E"
   },
   "source": [
    "Естественно, нам нужно изменить цикл train, потому что теперь модель\n",
    "возвращает кортеж `(logits, hidden_representation)`. Используя\n",
    "тензор входных данных, мы можем вывести их формы.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "id": "DWAHa8MDyy1E"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student logits shape: torch.Size([128, 10])\n",
      "Student hidden representation shape: torch.Size([128, 1024])\n",
      "Teacher logits shape: torch.Size([128, 10])\n",
      "Teacher hidden representation shape: torch.Size([128, 1024])\n"
     ]
    }
   ],
   "source": [
    "# Create a sample input tensor\n",
    "sample_input = torch.randn(128, 3, 32, 32).to(device) # Batch size: 128, Filters: 3, Image size: 32x32\n",
    "\n",
    "# Pass the input through the student\n",
    "logits, hidden_representation = modified_nn_light(sample_input)\n",
    "\n",
    "# Print the shapes of the tensors\n",
    "print(\"Student logits shape:\", logits.shape) # batch_size x total_classes\n",
    "print(\"Student hidden representation shape:\", hidden_representation.shape) # batch_size x hidden_representation_size\n",
    "\n",
    "# Pass the input through the teacher\n",
    "logits, hidden_representation = modified_nn_deep(sample_input)\n",
    "\n",
    "# Print the shapes of the tensors\n",
    "print(\"Teacher logits shape:\", logits.shape) # batch_size x total_classes\n",
    "print(\"Teacher hidden representation shape:\", hidden_representation.shape) # batch_size x hidden_representation_size"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![In Cosine Loss minimization, we want to maximize the cosine similarity\n",
    "of the two representations by returning gradients to the\n",
    "student:](https://pytorch.org/tutorials//../_static/img/knowledge_distillation/cosine_loss_distillation.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_Ll0Of5yyy1E"
   },
   "source": [
    "В нашем случае `hidden_representation_size` равно `1024`. Это карта фичей последнего сверточного слоя студента, и, как вы можете видеть, это входные данные для его классификатора. Для учителя это тоже `1024`, потому что мы сделали это с помощью `avg_pool1d` из `2048`.\n",
    "Потери в карте фичей, применяемые здесь, влияют только на вес студента до\n",
    "расчета основной функции потерь. Другими словами, это не влияет на классификатор\n",
    "студента. Модифицированный цикл обучения выглядит следующим образом:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "Ab2rTU0ayy1E"
   },
   "outputs": [],
   "source": [
    "def train_cosine_loss(teacher, student, train_loader, epochs, learning_rate, hidden_rep_loss_weight, ce_loss_weight, device):\n",
    "    ce_loss = nn.CrossEntropyLoss()\n",
    "    cosine_loss = nn.CosineEmbeddingLoss()\n",
    "    optimizer = optim.Adam(student.parameters(), lr=learning_rate)\n",
    "\n",
    "    teacher.to(device)\n",
    "    student.to(device)\n",
    "    teacher.eval()  # Teacher set to evaluation mode\n",
    "    student.train() # Student to train mode\n",
    "\n",
    "    for epoch in range(epochs):\n",
    "        running_loss = 0.0\n",
    "        for inputs, labels in train_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass with the teacher model and keep only the hidden representation\n",
    "            with torch.no_grad():\n",
    "                _, teacher_hidden_representation = teacher(inputs)\n",
    "\n",
    "            # Forward pass with the student model\n",
    "            student_logits, student_hidden_representation = student(inputs)\n",
    "\n",
    "            # Calculate the cosine loss. Target is a vector of ones. From the loss formula above we can see that is the case where loss minimization leads to cosine similarity increase.\n",
    "            hidden_rep_loss = cosine_loss(student_hidden_representation, teacher_hidden_representation, target=torch.ones(inputs.size(0)).to(device))\n",
    "\n",
    "            # Calculate the true label loss\n",
    "            label_loss = ce_loss(student_logits, labels)\n",
    "\n",
    "            # Weighted sum of the two losses\n",
    "            loss = hidden_rep_loss_weight * hidden_rep_loss + ce_loss_weight * label_loss\n",
    "\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            running_loss += loss.item()\n",
    "\n",
    "        print(f\"Epoch {epoch+1}/{epochs}, Loss: {running_loss / len(train_loader)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "nVSQgdGAyy1E"
   },
   "source": [
    "По той же причине нам нужно изменить нашу тестовую функцию. Здесь мы игнорируем\n",
    "скрытое представление, возвращаемое моделью."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "_TiNYZ9Nyy1E"
   },
   "outputs": [],
   "source": [
    "def test_multiple_outputs(model, test_loader, device):\n",
    "    model.to(device)\n",
    "    model.eval()\n",
    "\n",
    "    correct = 0\n",
    "    total = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in test_loader:\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "\n",
    "            outputs, _ = model(inputs) # Disregard the second tensor of the tuple\n",
    "            _, predicted = torch.max(outputs.data, 1)\n",
    "\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    accuracy = 100 * correct / total\n",
    "    print(f\"Test Accuracy: {accuracy:.2f}%\")\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "UogAARfkyy1F"
   },
   "source": [
    "В этом случае мы могли бы легко включить\n",
    "в одну и ту же функцию как извлечение знаний, так и минимизацию косинусных потерь. Обычно для\n",
    "достижения более высокой производительности в парадигмах учитель-ученик используются комбинированные методы. На\n",
    "данный момент мы можем обучить модели."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "id": "oCiMD5_Lyy1F"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10, Loss: 1.305133652809026\n",
      "Epoch 2/10, Loss: 1.071263348964779\n",
      "Epoch 3/10, Loss: 0.9721636122754772\n",
      "Epoch 4/10, Loss: 0.8992896465694203\n",
      "Epoch 5/10, Loss: 0.8461023011170995\n",
      "Epoch 6/10, Loss: 0.7991485271002631\n",
      "Epoch 7/10, Loss: 0.7561488685095706\n",
      "Epoch 8/10, Loss: 0.71864186757056\n",
      "Epoch 9/10, Loss: 0.6837123874813089\n",
      "Epoch 10/10, Loss: 0.655079073308374\n",
      "Test Accuracy: 70.93%\n"
     ]
    }
   ],
   "source": [
    "# Train and test the lightweight network with cross entropy loss\n",
    "train_cosine_loss(teacher=modified_nn_deep, student=modified_nn_light, train_loader=train_loader, epochs=10, learning_rate=0.001, hidden_rep_loss_weight=0.25, ce_loss_weight=0.75, device=device)\n",
    "test_accuracy_light_ce_and_cosine_loss = test_multiple_outputs(modified_nn_light, test_loader, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Teacher accuracy: 74.23%\n",
      "Student accuracy without teacher: 70.23%\n",
      "Student accuracy with CE + KD: 70.34%\n",
      "Student accuracy with CE + CosineLoss: 70.93%\n"
     ]
    }
   ],
   "source": [
    "print(f\"Teacher accuracy: {test_accuracy_deep:.2f}%\")\n",
    "print(f\"Student accuracy without teacher: {test_accuracy_light_ce:.2f}%\")\n",
    "print(f\"Student accuracy with CE + KD: {test_accuracy_light_ce_and_kd:.2f}%\")\n",
    "print(f\"Student accuracy with CE + CosineLoss: {test_accuracy_light_ce_and_cosine_loss:.2f}%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "n6SIeeFIyy1K"
   },
   "source": [
    "Заключение\n",
    "==========\n",
    "\n",
    "Ни один из вышеперечисленных методов не увеличивает количество параметров\n",
    "сети или время вывода, поэтому увеличение производительности достигается за счет\n",
    "небольших затрат на вычисление градиентов во время обучения. В\n",
    "приложениях ML мы в основном заботимся о времени вывода, поскольку обучение\n",
    "происходит до развертывания модели. Если наша упрощенная модель все еще\n",
    "слишком сложна для внедрения, мы можем применить другие идеи, такие как\n",
    "квантование после обучения **об этом в следующих лекциях**. Идеи Knowledge Distillation могут быть применены во многих задачах, а не только в классификации, и вы можете поэкспериментировать с величинами\n",
    "например, коэффициенты, температура или количество нейронов. Не стесняйтесь изменять\n",
    "любые цифры из ноутбука, но имейте в виду, что при изменении\n",
    "количества нейронов / фильтров может возникнуть несоответствие архитектур.\n",
    "\n",
    "Основные статьи:\n",
    "\n",
    "-   [Hinton, G., Vinyals, O., Dean, J.: Distilling the knowledge in a\n",
    "    neural network. In: Neural Information Processing System Deep\n",
    "    Learning Workshop (2015)](https://arxiv.org/abs/1503.02531)\n",
    "-   [Romero, A., Ballas, N., Kahou, S.E., Chassang, A., Gatta, C.,\n",
    "    Bengio, Y.: Fitnets: Hints for thin deep nets. In: Proceedings of\n",
    "    the International Conference on Learning\n",
    "    Representations (2015)](https://arxiv.org/abs/1412.6550)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
